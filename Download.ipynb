{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading with urllib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99.9% 183599104 / 183736339"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99.9% 183607296 / 183736339\r",
      " 99.9% 183615488 / 183736339\r",
      " 99.9% 183623680 / 183736339\r",
      " 99.9% 183631872 / 183736339\r",
      " 99.9% 183640064 / 183736339\r",
      "100.0% 183648256 / 183736339\r",
      "100.0% 183656448 / 183736339\r",
      "100.0% 183664640 / 183736339\r",
      "100.0% 183672832 / 183736339\r",
      "100.0% 183681024 / 183736339\r",
      "100.0% 183689216 / 183736339\r",
      "100.0% 183697408 / 183736339\r",
      "100.0% 183705600 / 183736339\r",
      "100.0% 183713792 / 183736339\r",
      "100.0% 183721984 / 183736339\r",
      "100.0% 183730176 / 183736339\r",
      "100.0% 183738368 / 183736339\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "def reporthook(blocknum, blocksize, totalsize):\n",
    "    readsofar = blocknum * blocksize\n",
    "    if totalsize > 0:\n",
    "        percent = readsofar * 1e2 / totalsize\n",
    "        s = \"\\r%5.1f%% %*d / %d\" % (\n",
    "            percent, len(str(totalsize)), readsofar, totalsize)\n",
    "        sys.stderr.write(s)\n",
    "        if readsofar >= totalsize: # near the end\n",
    "            sys.stderr.write(\"\\n\")\n",
    "    else: # total size is unknown\n",
    "        sys.stderr.write(\"read %d\\n\" % (readsofar,))\n",
    "        \n",
    "url = 'https://archive.apache.org/dist/drill/drill-1.6.0/apache-drill-1.6.0.tar.gz '\n",
    "print(\"downloading with urllib\")\n",
    "urllib.request.urlretrieve(url, 'code.zip', reporthook)\n",
    "#urllib.request.urlretrieve(url, \"code.zip\")\n",
    "print('done') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading: apache-drill-0.4.0-incubating-src.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38.8%  573440 / 1477479"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sys\n",
    "\n",
    "def reporthook(blocknum, blocksize, totalsize):\n",
    "    readsofar = blocknum * blocksize\n",
    "    if totalsize > 0:\n",
    "        percent = readsofar * 1e2 / totalsize\n",
    "        s = \"\\r%5.1f%% %*d / %d\" % (\n",
    "            percent, len(str(totalsize)), readsofar, totalsize)\n",
    "        sys.stderr.write(s)\n",
    "        if readsofar >= totalsize: # near the end\n",
    "            sys.stderr.write(\"\\n\")\n",
    "    else: # total size is unknown\n",
    "        sys.stderr.write(\"read %d\\n\" % (readsofar,))\n",
    "\n",
    "project_url = 'https://archive.apache.org/dist/drill/'\n",
    "parent_path = urlopen(project_url)\n",
    "parent_content = parent_path.read().decode('utf-8')\n",
    "soup = BeautifulSoup(parent_content, 'html.parser')\n",
    "\n",
    "pattern1 = re.compile('drill-(.)+\\/')\n",
    "src_pattern = re.compile('apache-drill-(\\d\\.)+\\d(.)*-src.tar.gz$')\n",
    "binary_pattern = re.compile('apache-drill-(\\d\\.)+\\d(.)*[^src].tar.gz$')\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    matched = pattern1.match(link.get('href'))\n",
    "    if matched is not None:\n",
    "        final_url = project_url + matched.group()\n",
    "        final_path = urlopen(final_url)\n",
    "        final_content = final_path.read().decode('utf-8')\n",
    "        soup2 = BeautifulSoup(final_content, 'html.parser')\n",
    "        for link2 in soup2.find_all('a'):\n",
    "            matched2 = src_pattern.match(link2.get('href'))\n",
    "            if matched2 is not None:\n",
    "                print('downloading: '+ matched2.group())\n",
    "                urllib.request.urlretrieve(final_url + matched2.group(), matched2.group(), reporthook)\n",
    "                print('done: ' + matched2.group())\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
